{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab0757a2-86b8-4ff4-baac-a5d4013d4f18",
   "metadata": {},
   "source": [
    "# Model a Multinomial Logistic Regression in Python\n",
    "\n",
    "This notebook will perform multinomial logistic regression on our sample data.  We have a decent amount of data, though there is some skew that we'll have to watch out for:  two of our classes are under-represented in the dataset.\n",
    "\n",
    "For prior analysis, we've used `pandas`, `numpy`, and a variety of functions from `scikit-learn`.  Now we'll add two more functions from `sklearn.model_selection`:  `RepeatedStratifiedKFold` and `cross_val_score`.  These aren't mandatory for multinomial logistic regression but will help us get a better idea of how the model fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce8801-ed2e-468c-8c09-99ae72b97f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24daf9f-72ee-4dec-a933-5ac9006a550e",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We will read in the same dataset as what we have in R, so instead of blanks, we'll get those `NA` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb15aae-e27b-45a3-92bc-3df03b3101bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ExtendedAttackData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad0803-572e-42db-8d93-0c341372a068",
   "metadata": {},
   "source": [
    "The good news is that Python interprets those `NA` values as `NaN`, just as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ef9bd-a329-42a5-9430-53f504e43525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4040b4-4c2a-47c4-bcec-7b6e7e924ac7",
   "metadata": {},
   "source": [
    "Before performing any string imputation or column transformations, let's take `AttackType` and make it our label.  We'll also drop `malicious` from the feature set, as it won't be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6b975-c407-4dd0-8008-4f6ce3a026f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df['AttackType']\n",
    "x = df.drop(['AttackType', 'malicious'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a973a-994c-4dbc-8c36-a60adfefc6ee",
   "metadata": {},
   "source": [
    "Just as before, we'll create an ordinal encoder and transform string values into ordinals.  Then, we'll impute missing numeric values with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e73184-6c08-48f9-8fb6-61d40b62b4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "string_cols = x.select_dtypes(include=[object]).columns.values\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(x[string_cols])\n",
    "x[string_cols] = enc.transform(x[string_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd94bc6-4c2c-42f8-a709-580bb7879e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "x[:] = imp_mean.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d425d71-0be0-4912-be00-a5ba1875947f",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation\n",
    "\n",
    "Before we fit our model and run test data against it, let's use a new function:  `cross_val_score()`, which performs k-fold cross-validation.  We'll split our data 10 ways (i.e., 10-fold) with the `RepeatedstratifiedKFold` class.  We do this three separate times with random subsets of the data and generate a value for accuracy for each split attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a12e5-ee26-4cae-9884-7df5098dba77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=106842, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da34dc7-1d33-4267-995f-62801e75220e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(clf, x, y, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491c6f7-0161-4904-8372-2a465de798e0",
   "metadata": {},
   "source": [
    "Here are the resulting scores for the 30 separate tests.  Ideally, the accuracy remains very similar across each split--that would be a good indicator to us that we have stable results and won't drastically change with a different random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9c463-3bcb-4fd5-b9ed-ab3fce42e641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c8695-8676-492e-96c7-0545f7c590bf",
   "metadata": {},
   "source": [
    "We can also aggregate these results, showing things like the mean and standard deviation of the results.  As we can see, the accuracy is quite stable, so it's a good sign for us and can provide us the guidance to go ahead with our proper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19792266-840a-4373-912f-0df635ce8ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(n_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e23a9-e54b-4d8b-879c-de304ac4e9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.std(n_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af4e2d-b6ce-472d-8291-af2ad8d20e07",
   "metadata": {},
   "source": [
    "## Evaluation against Test Data\n",
    "\n",
    "Now we can split our data into training and test subsets, fit our model to the training data, and generate predictions from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b4acf-2e61-4a17-956c-bf2eae04db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75a434-d76f-426e-b5fd-95c4c6f86e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c684f8-8cf0-4810-ad0a-428e54a1a3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1058d7-46b8-4c3e-aae2-77366a72252a",
   "metadata": {},
   "source": [
    "With our predictions in hand, we can use the `confusion_matrix()` function to generate a confusion matrix.  The findings here are interesting:  unlike R, we can see a real difficulty in separating two of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31022da5-ac7a-4924-9beb-131bb313ad52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60625-ffd8-4207-86c3-58f2bf174ecb",
   "metadata": {},
   "source": [
    "Looking at the classification report, we see that the Python logistic regression algorithm does a terrible job of separating regular denial of service attacks from broadcast denial of service attacks.  Because of this, we get every one of the classic DoS predictions wrong.  It does a great job of getting everything else correct, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87622d-48f6-43f2-b45c-a2e7fcc570c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed83bf-72d4-4220-84ab-7d2118cdae64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
