{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f6a28c-685b-431d-86a2-4f92bfcd5cb8",
   "metadata": {},
   "source": [
    "# Model a Logistic Regression in R\n",
    "\n",
    "This notebook will perform logistic regression on our sample data.  The total number of sample records is not great, though given that most of our input features have very few unique values, it's not quite as bad as it would first appear to be.\n",
    "\n",
    "In addition to the `tidyverse` package, we will also use two more packages: `caret`, a general-purpose package which helps data scientists with common tasks; and `mice`, a library for imputing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d905ce-2b39-4fc9-ae6c-3cead4a082ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "library(mice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450ca86-a4f2-4572-8409-d37827e3260e",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "This is the cleaned-up attack data from our prior notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511d735-c5e5-4b5c-bd21-5e1a296c583f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attack_data <- read_csv(\"../1553_dos_attack1_R_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7a1f2-6023-450a-aa1d-6e4dd7aab874",
   "metadata": {},
   "source": [
    "The next step we will perform is shuffling the order of the data.  This way, our training and test choices are randomizes within the dataset so we reduce the risk of something in our test data that the training side never saw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7bb321-9503-48e3-9321-9afe2e819e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(184856)\n",
    "rand_attack_data <- attack_data[sample(nrow(attack_data)), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517bca3-898a-4598-a34e-53b580f6e5b3",
   "metadata": {},
   "source": [
    "## Impute Missing Data\n",
    "\n",
    "The next thing we'll want to do is impute data.  Because we have data missing from our dataset, that can throw off our logistic regression.  R's logistic regression function can support missing values, but the results won't be as effective as if we fill in the gaps.  First, let's look at the pattern of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbd652-0aaf-4251-935a-150b4673d2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "md.pattern(rand_attack_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b134260-863a-4283-b2f8-7d088bb2f2e6",
   "metadata": {},
   "source": [
    "After finding the pattern of the data, we'll perform imputation, using the default of 5 imputed datasets (`m=5`), setting the max number of iterations to 50 (`maxit=50`), and the method to predictive mean matching (`meth='pmm'`).  These are fairly standard settings, so we could tweak them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368648b-9c0e-43e2-85f4-b58e6969d9a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputed_data <- mice(rand_attack_data, m=5, maxit=50, meth='pmm', seed=103409)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75aa114-6663-43da-95fb-eafe5cccc950",
   "metadata": {},
   "source": [
    "Once we've generated the pattern, we can complete our missing data by retrieving the first complete data set from MICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640141d7-d901-4910-a4d8-895a873a65fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completed_data <- complete(imputed_data, action=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540ee83-b58d-4063-a2ac-c5a0d457af7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "After doing this, we still have two columns with missing values:  `sa` and `ssa`.  We'll set missing values to 0 for `sa` and 20 for `ssa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fd93b-c0c3-41a5-8e80-ef909b651059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completed_data$sa[is.na(completed_data$sa)] <- 0\n",
    "completed_data$ssa[is.na(completed_data$ssa)] <- 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b0510-23f6-4060-b6c8-22710fc2b4df",
   "metadata": {},
   "source": [
    "## Partitioning the Data\n",
    "\n",
    "The `createDataPartition` allows us to split data on some variable.  Typically, this would be a categorical input variable, to increase the likelihood that we get coverage of its potential values in the training and test data, as a new category on the test side can cause prediction errors.\n",
    "\n",
    "In this case, I'll split on the label because there is some imbalance in in the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc18353-29aa-4e2b-af26-d6acd41645ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainIndex <- caret::createDataPartition(completed_data$malicious, p = 0.7, list  = FALSE, times = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739b0de-eeca-4c1d-a87d-1970c5792db3",
   "metadata": {},
   "source": [
    "The data partition gives us back an index.  We can use that index to split our randomized attack data into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769d6fc-3055-4042-ba19-62fd9bbf3bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data <- completed_data[trainIndex,]\n",
    "test_data <- completed_data[-trainIndex,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27884f34-6329-4d55-b38b-553ec8693414",
   "metadata": {},
   "source": [
    "I want to see approximately 70% in the training dataset and approximately 30% in the test dataset.  That's the `p = 0.7` parameter in the prior call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5e340-d56e-4123-a781-11cce27c6f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrow(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922c1cc-21a3-4319-93e6-f232f9a90aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrow(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48547f64-6da1-411b-9b54-63a5d9a91360",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "\n",
    "Training a model is very easy to do with R.  The `glm()` (Generalized Linear Model) function allows us to create (among others) linear, logistic, and Poisson regressions using the same common syntax.  For logistic regression, the family is `binomial`, meaning that our label takes on one of two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d5d76-131e-47d4-9a41-50c0d5c6ad67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model <- glm(malicious ~ dw0 + msgTime + rxSts + sa + gap + dsa + ssa + txSts + da + wc, data=train_data, family=binomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11c75e-78b0-4c41-bb0a-49325006da2e",
   "metadata": {},
   "source": [
    "Now that we have trained the model, we can review the outputs.  Note that, if we did not impute missing values, several of our variables would return `NA` for the coefficient.  Because we imputed missing values, we get weights for each input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588f99f-ce00-4104-82cf-cd8338eab5ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8dfc10-6287-43a0-84e2-f8c2b9174416",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "We have a left-over test data set we can use to generate predictions.  This will give us a good idea of how well we did in our logistic regression exercise.  Note that we need to include `type=\"response\"` to get back probability data scaled between 0 and 1; otherwise, we will get back a numeric value representing how far along the logistic curve we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8cb442-8997-4c63-89c6-d27ebc77a1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_pred <- predict(model, test_data, type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ecaa7-5665-4d36-9d69-59a56ea74ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(model_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ac36d-f6b7-4402-8ba9-17963f3ff563",
   "metadata": {
    "tags": []
   },
   "source": [
    "The responses are a bit tough to read but they are close to 1 or 0.  What we'll do is convert these into logical `TRUE` and `FALSE` statements based on whether the prediction is greater than or equal to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8224f68-d73b-41af-8cf5-674789350eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_malicious <- case_when(model_pred >= 0.5 ~ TRUE, is.na(model_pred) ~ NA, .default=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298664b1-33a2-403e-b61b-d2c9ac410d04",
   "metadata": {},
   "source": [
    "The `pred_malicious` column gives us our predicted values.  We can add this on to our test data so we can see in one go the input data, our prediction of whether that traffic was malicious, and whether the traffic actually was malicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21921995-fac6-477f-96cc-b458d35d5662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcomes <- cbind(as.data.frame(pred_malicious), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c12b17-2133-45dc-8275-985f2d850c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad071bf5-e4c3-474b-9a1c-1ec849c85175",
   "metadata": {},
   "source": [
    "After getting the number of rows, we next want to find the number of correct predictions, which is cases where the value of `pred_malicious` is the same as `malicious`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b73f2c-7ce6-4691-9d5b-c8236a3727d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_rows <- nrow(outcomes)\n",
    "correct_predictions <- sum(outcomes$pred_malicious == outcomes$malicious)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ee90d-dbc7-4a06-b749-7a25ccd4298f",
   "metadata": {},
   "source": [
    "Finally, let's show these results to see how many we got correct, how many predictions there were, and our **accuracy**, which is the number of correct predictions divided by the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0e6e0-45a0-4689-9cb0-1e17b80134ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c(correct_predictions, num_rows, correct_predictions / num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cd813-ff58-4d3e-8704-32844feecfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
